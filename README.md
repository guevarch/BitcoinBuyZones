# Introduction

"Bitcoin is a bank in cyberspace, run by incorruptible software, offering a global, affordable, simple, & secure savings account to billions of people that don’t have the option or desire to run their own hedge fund." - Michael Saylor [^4]

On 3 January 2009, the bitcoin network was created when Nakamoto mined the starting block of the chain, known as the genesis block. Embedded in the coinbase of this block was the text "The Times 03/Jan/2009 Chancellor on brink of second bailout for banks". Bitcoin is a decentralized digital currency that can be transferred on the peer-to-peer bitcoin network. Bitcoin transactions are verified by network nodes through cryptography and recorded in a public distributed ledger called a blockchain. The cryptocurrency was invented in 2008 by an unknown person or group of people using the name Satoshi Nakamoto. The currency began use in 2009,] when its implementation was released as open-source software.[^18]

I chose this topic because I believe bitcoin is a tool for economic sovereignty, individual property rights and financial inclusion. We can see evidence of this in the adoption rates in emerging markets or developing nations. We can see the fastest adoption are in developing nations such as Nigeria, Thailand and the Philippines. The image below also shows that the exponential growth rate of bitcoin is very similar to the growth of the internet from 1994 to present. In fact, Bitcoin's network growth rate is faster than the internet.[^5,9,3]

<p align="center">
  <img src="static\developingnationsadoption.webp" width="350" title="hover text">
  <img src="static\btcgrowth.jpg" width="350" title="hover text">
  <img src="static\btcgrowth2.jpeg" width="350" title="hover text">

</p>

The first objective is to use the Prophet time series model to forecast price, wallets and value(according to Metcafe’s Law) up to 2024. The second objective is to determine if the current price is overvalued or undervalued compared to Metcafe’s Law of Network Adoptions and Moving averages.

# Method

The first step in the process is to find the data. The data sources included market data such as price, open, close, adjusted close, and date. Other data sources that were needed for the analysis were active addresses, coin supply, and wallets. The file types are comma separated values. Next, is to create a database in PostgreSQL and create tables to house the csv data. A join function was used to combine two csv tables and psycopg2 was used to connect PostgreSQL to pandas dataframe. The new dataframe was further cleaned, cured and prepared for analysis and Prophet time series and supervised machine learning. 

List Data Sources: 

- Circulating Bitcoin: https://www.blockchain.com/explorer/charts/total-bitcoins
- Wallets: https://www.blockchain.com/explorer/charts/my-wallet-n-users
- Bitcoin Market Data: https://www.investing.com/crypto/bitcoin and Yahoo Finance
- Active Addresses: https://studio.glassnode.com/metrics

# Results

## Formulas and Terminology

<pre><code>
df['Metcafe']=df['address']**2
df['value'] = df['Metcafe']/df['mined']
df["value"] = df["value"].map("{:.2f}".format)
df['value']=df['value'].astype("float")
df['networkvalue'] = df["price"] - df["value"]
</code></pre>

### Value = Metcafe's law = (Active Addressess)^2

The value of a network is famously accredited to Bob Metcalfe, the inventor of Ethernet and founder of the computer networking company 3Com. Metcalfe’s Law states that a network’s value is proportional to the square of the number of its users. It also reveals when Bitcoin has been overvalued.  Wheatley and co point to four occasions when Bitcoin has become overvalued and then crashed; in other words, when the bubble has burst. [^13]

### Price = Market Cap/Current Supply

For a cryptocurrency like Bitcoin, market capitalization (or market cap) is the total value of all the coins that have been mined. It’s calculated by multiplying the number of coins in circulation by the current market price of a single coin. This is very similar to stock valuations, shares x stock price = market cap. [^2]

Moreover, the circulating supply of a cryptocurrency can be used for calculating its market capitalization, which is generated by multiplying the current market price with the number of coins in circulation. So if a certain cryptocurrency has a circulating supply of 1,000,000 coins, which are being traded at $5.00 each, the market cap would be equal to $5,000,000. [^2]

### Network Value = Value - Price

Network Value is simply subtracting the current value or Metcalfe's law by the current price.

## Preprocessing

### Determining Stationary

Stationary Time Series - The observations in a stationary time series are not dependent on time. Time series are stationary if they do not have trend or seasonal effects. Summary statistics calculated on the time series are consistent over time, like the mean or the variance of the observations. When a time series is stationary, it can be easier to model. Statistical modeling methods assume or require the time series to be stationary to be effective.[^1,6, 17]

Bitcoin's very nature is time dependant. Every four years Bitcoin goes through a halvening of block reward. The image below shows the issuance schedule of bitcoin. Each halving lowers Bitcoin's inflation rate. The orange line is Bitcoin's inflation rate during a given period, while the blue line is the total number of bitcoins issued. The Bitcoin halving is scheduled in block height, not date.[^10, 14]
The halving happens every 210,000 blocks. The 2024 halving will happen on block 840,000. The current Bitcoin block subsidy is 6.25 bitcoins per block. When block 840,000 is hit in 2024, the subsidy will drop to 3.125 bitcoins (BTC) per block. All 21 million bitcoins (BTC) will be mined by 2140. But more than 98% will be mined by 2030.

<p align="center">
  <img src="static\bitcoininflation.webp" width="350" title="hover text">
 </p>

Observations from a non-stationary time series show seasonal effects, trends, and other structures that depend on the time index. Summary statistics like the mean and variance do change over time, providing a drift in the concepts a model may try to capture. Classical time series analysis and forecasting methods are concerned with making non-stationary time series data stationary by identifying and removing trends and removing seasonal effects. [^1,6, 17]

Mean and Variance Test = non stationary, large differences in mean and variances.
Data was split into two and ran mean and var tests.[^1,6, 17,7]

<pre><code>
Mean and Var Test Linear
mean1 = 230.57, mean2 = 16936.32
variance1=61688.13, variance2=288670101.60
</code></pre>

Histogram Linear

<p align="center">
  <img src="static\histogramlinear.png" width="350" title="hover text">
</p>

Non Gaussian(Normal Bell) curve indicates that this squashed distribution of the observations may be another indicator of a non-stationary time series. Reviewing the plot of the time series again, we can see that there is an obvious seasonality component, and it looks like the seasonality component is growing. This may suggest an exponential growth from season to season. A log transform can be used to flatten out exponential change back to a linear relationship.[^1,6, 17,7]

Histogram Log

<p align="center">
  <img src="static\histogramlog.png" width="350" title="hover text">

</p>

Log form of the price helps reduce the mean and variance but the seasonal nature is still present in the data. 

<pre><code>
Mean and Var Test Log
mean1 = 3.963961, mean2=9.174585
variance1=5.856168, variance2=1.358006
</code></pre>

Augmented Dickey-Fuller Test

The null hypothesis of the test is that the time series can be represented by a unit root, that it is not stationary (has some time-dependent structure). The alternate hypothesis (rejecting the null hypothesis) is that the time series is stationary.

Null Hypothesis (H0): If failed to be rejected, it suggests the time series has a unit root, meaning it is non-stationary. It has some time dependent structure.
Alternate Hypothesis (H1): The null hypothesis is rejected; it suggests the time series does not have a unit root, meaning it is stationary. It does not have time-dependent structure.[^1,6, 17,7]

Linear ADF - Running the example prints the test statistic value of -1.769203. The more negative this statistic, the more likely we are to reject the null hypothesis (we have a stationary dataset). We can see that our statistic value of  -1.769203 is greater than the value of -3.432 at 0.05. This suggests that we cannot reject the null hypothesis with a significance level of less than 0.05. Not rejecting the null hypothesis means that the process has unit root, and in turn that the time series is non stationary or does have time-dependent structure[^1,6, 17,7]

<pre><code>
ADF Statistic: -1.769203
p-value: 0.395855
Critical Values:
	1%: -3.432
	5%: -2.862
	10%: -2.567_test_split(X,
   y, random_state=1, stratify=y)
</code></pre>

A p-value less than 0.05 is typically considered to be statistically significant, in which case the null hypothesis should be rejected. A p-value greater than 0.05 means that deviation from the null hypothesis is not statistically significant, and the null hypothesis is not rejected. In this case, p value for the log of the prices has a low enough value for the null hypothesis to be rejected. The -value can be further reduced by taking the diff of the log value but Prophet, unlike ARIMA, doesn't factor that method into its parameters. For this analysis, this p-value would suffice.[^1,6, 17,7]

<pre><code>
ADF Statistic: -3.182831
p-value: 0.021000
	1%: -3.432
	5%: -2.862
	10%: -2.567
</code></pre>


## Prophet

Prophet is specifically designed for business time series prediction. It achieves very good results for the stock data but it can fail on time series datasets from other domains. In particular, this holds for time series where the notion of calendar date is not applicable and we cannot learn any seasonal patterns. Prophet’s advantage is that it requires less hyperparameter tuning as it is specifically designed to detect patterns in business time series[^11]. Due to the hyperbolic exponential growth of Bitcoins price and adoption, after 2024, upper/lower/middle bound predictions "fray" - as seen on the bitcoin log price prediction and the bitcoin value prediction.

The process for prophet is to create a df_train, fitting it into a prophet model, and m.predict forecast. The forecast function splits the y value into yhat, yhat_lower and yhat_upper. This creates upper, lower and middle projections. By using m.plot(forecast), the df_train and forecast values are plotted. However, there is another method called insample wherein the analyst can set the pd.date_range of the prediction.[^11]. Insample was used to predict prices, wallets and value.


### Results LogPrices and Value

<p align="center">
  <img src="static\prices.png" width="400" title="hover text">
  <img src="static\logprices.png" width="400" title="hover text">
  <img src="static\value.png" width="400" title="hover text">
  <img src="static\wallets.png" width="400" title="hover text">
</p>

We can see below that log prices do in fact produce a better r2, mse, and mbe score compared to the linear prices. The mean squared error (MSE) tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them. The mean absolute error is the average difference between the observations (true values) and model output (predictions).  In summary, the lower the mse and mbe the better the forecast. However, I am a bit skeptical of these values. Even though on paper these are great results they could be due to overfitting[^19]. The same goes for the scores of Value. They look too good to be true which they probably are.  

<pre><code>
LogPrices
r2_score = 0.9866
mean_squared_error =  0.1390
mean_absolute_error = 0.2809

Linear Prices 
r2_score = 0.7455
mean_squared_error =  54484853.20
mean_absolute_error = 4327.367

Value
r2_score = 0.988
mean_squared_error = 0.115
mean_absolute_error = 0.249

Wallets
r2_score = 0.997​
mean_squared_error = 0.0741
mean_absolute_error = 0.1325

</code></pre>

## Logistic Regression Using Value(Metcalfe's Law) 

### Hyperparameter Tuning

<pre><code>
Best: 0.948246 using {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}
</code></pre>
#### LogisticRegression

Metcalfe's Law isn't exactly the best indicator for short (1-12 months) term trading as seen in the image below. The orange line shows that the network is undervalued compared to the market price, and the red shows that it is overvalued compared to the market price. The true value of Metcalfe's Law is for long term investors that have a ~10-20 year outlook that believe that network growth and usage will penetrate the population in the same fashion as the internet in the 90-00's. Since there are only two outputs or binary outcomes, logistic regression should work well with this dataset. Nonetheless, this metric still provides good insight into network valuation. It is interesting to see that overvaluation occurs in the beginning of the price history (2011 ish) and during the summer of 2021. In 2011, there were few users in the network and the chain had little value, Satoshi and a few other cypherpunks were the few users at the time[^18]. However in 2021, this was probably due to excess leverage from the FTX/Alameda saga we are seeing unwinding today. The price was drawn up due to "paper" or fractional bitcoin trading rather than user generated growth or active addresses using the network. 


<pre><code>
df['status'].value_counts()
0    4118
1     268
</code></pre>

As seen below, the model has good precision and recall scores for undervalued network. Conversely, the scores are all lower when testing for overvalued network. Both precision and recall scores were down from predicting undervaluation. The combination of the model and the metric is a good indicator for excess leverage in the system and a good indicator for active user usage as it relates to price/value.


<p align="center">
  <img width="460" height="300" src="static\bitcoinvaluestatus.png">
</p>

<pre><code>

Confusion Matrix
          Predicted 0	Predicted 1
Actual 0	  1242	      0
Actual 1	    69	      5

Training Score: 0.942
Testing Score: 0.947

              precision    recall  f1-score   support

           0       0.95      1.00      0.97      1242
           1       1.00      0.07      0.13        74

    accuracy                           0.95      1316
   macro avg       0.82      0.61      0.55      1316
weighted avg       0.94      0.95      0.93      1316

balanced_accuracy_score: 0.5337
accuracy_score: 0.947
        
</code></pre>


## Logistic Regression Using Mean of 50, 200, and 300 day moving averages with expanding means

### Hyperparameter Tuning

<pre><code>
Best: 1.000000 using {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}
</code></pre>

#### LogisticRegression

The 200 day moving average is widely used by traders because it is seen as a good indicator of the long term trend in the market. If price is consistently trading above the 200 day moving average, this can be viewed as an upward trending market. Markets consistently trading below the 200 day moving average are seen to be in a downtrend. The 200 day moving average can be used to identify key levels in the market that have been respected before. Often in the market, price will approach and bounce off the 200 day moving average and continue in the direction of the existing trend[^16]. Therefore, the 200 day moving average can be viewed as dynamic support or resistance. For this analysis, I took the mean of the 50, 200, and 300 day moving averages rather than simply using the 200 day. Again, since we are dealing with binary outcomes, logistic regression should work well with this dataset. 

Something to note, the value counts show a more even/balanced over/undervaluation compared to the previous metric. 

The results from the model show that the predictions are 100% accurate for over/undervaluation. I think this is more reflective of the metric rather than the model. No model is perfect and this one is no different. I think this model/metric can be used for medium term outlook ~12months to 3 years.

<pre><code>
df['status'].value_counts()
1    2483
0    1642
</code></pre>

<p align="center">
  <img width="460" height="300" src="static\movingaverages.png">
</p>

<pre><code>

Confusion Matrix
	      Predicted 0	Predicted 1
Actual 0	     494	    0
Actual 1	      0	    744

Training Score: 1.0
Testing Score: 1.0

              precision    recall  f1-score   support

           0       1.00      1.00      1.00       494
           1       1.00      1.00      1.00       744

    accuracy                           1.00      1238
   macro avg       1.00      1.00      1.00      1238
weighted avg       1.00      1.00      1.00      1238

balanced_accuracy_score: 1.0
accuracy_score: 1.0
</code></pre>


## Bonus Buy Zones 

#### OneVsRestClassifier

I wanted to create a classification model using OneVsRestClassifier. OneVsRestClassifier can also be used for multilabel classification, since we are dealing with 4 different labels/classes, I think this would be a good testing model. To do this I first calculated a move% using the current price and the meanavge. Then I used the describe method to find the standard deviations and quartile ranges of the move% to create bins for group names. The group names are "Severely Oversold","Oversold", "Neutral","Overbought" based on the standard deviations % from the price to the meanaverage.[^16]

<pre><code>
df['price-meanavge']=df['price'] - df['meanavge']
df['move%'] = df['price-meanavge']/(df['price'] + df['meanavge'])

bins = [-0.43, -0.1, 0, 0.1, 0.43]
group_names = ["Severely Oversold","Oversold", "Neutral","Overbought"]
df["Valuation"] = pd.cut(df["move%"], bins, labels=group_names)
</code></pre>

The results show fairly straight forward predictions for Severely Oversold(0) and Overbought(3), but for Oversold(1) and neutral(2) the predictions were mixed. This is understandable due to the unpredictability of bitcoin and of the overall market in general. The combination of the model and the metric can be useful for determining Severely Oversold and Overbought zones. Investors that have a medium term horizon could use this metric/model for placing larger timed investments rather than dollar cost averaging. 

<pre><code>
Confusion Matrix
          Predicted 0	Predicted 1	Predicted 2	Predicted 3
Actual 0	       232	      0	        0        	0
Actual 1	        1	        28	      247 	    0
Actual 2	        0	        0	        285	      1
Actual 3	        0	        0	        2	        411
Training Score: 0.81782
Testing Score: 0.7920
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       232
           1       1.00      0.10      0.18       276
           2       0.53      1.00      0.70       286
           3       1.00      1.00      1.00       413

    accuracy                           0.79      1207
   macro avg       0.88      0.77      0.72      1207
weighted avg       0.89      0.79      0.74      1207

balanced_accuracy_score: 0.773
accuracy_score: 0.792

</code></pre>

<p align="center">
  <img width="460" height="300" src="static\buyzones.png">
</p>

# Conclusion

The objective is to use the Prophet time series model to forecast price, wallets and value(according to Metcalfe’s Law) up to 2024. The second objective is to determine if the current price is overvalued or undervalued compared to Metcalfe’s Law of Network Adoptions and Moving averages, and buy zones. Bitcoin is very unique because it behaves like an asset and a network, therefore making the task of price predictions and testing for network valuation very daunting. Because of its complex nature, not one metric/model can be used to tackle this feat, it must be a combination of price behavior, technical analysis, network and user adoption. The combination of prophet time series forecasting of price, wallets and value, Logistic Regression of over/undervaluation, and moving averages and finally OneVsRestClassifier for buy zones are suitable ways to evaluate the value of the asset and network. In to build on this project or future projects regarding this subject matter, I would incorporate other technical metrics such as price on shorter time frames, broad based M2 money supply, compare to other assets such as gold, tech stocks, major indexes and other onchain analytical metrics. I would also use other more advanced machine learning methods such as ARIMA and LTSM for price predictions and forecasts. 


# References

1. 9.1 Stationarity and differencing | Forecasting: Principles and Practice (3rd ed). (n.d.). https://otexts.com/fpp3/stationarity.html

2. Academy, B. (n.d.). Circulating Supply. Binance Academy. https://academy.binance.com/en/glossary/circulating-supply
arXiv, E. T. F. T. (2020, April 2). How network theory predicts the value of Bitcoin. MIT Technology Review. https://www.technologyreview.com/2018/03/29/67091/how-network-theory-predicts-the-value-of-bitcoin/

3. Author At, |. (n.d.). Top Cryptocurrency Countries by Adoption (2022 Data). Bankless Times. https://www.banklesstimes.com/cryptocurrency/top-countries-leading-in-cryptocurrency-adoption/

4. Bitcoin. (n.d.). MicroStrategy. https://www.michael.com/en/bitcoin

5. Bitcoin Inflation : Woobull Charts. (n.d.). https://charts.woobull.com/bitcoin-inflation/

6. Brownlee, J. (2016, December 30). How to Check if Time Series Data is Stationary with Python. Machine Learning Mastery. https://machinelearningmastery.com/time-series-data-stationary-python/

7. Classification: Precision and Recall  |  Machine Learning  |. (n.d.). Google Developers. https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall

8. insidelearningmachines. (2022, June 12). Mean Absolute Error. Inside Learning Machines. https://insidelearningmachines.com/mean_absolute_error/

9. Isige, J. (2021, February 10). Bitcoin on track for mass adoption as it grows faster than the internet. FXStreet. https://www.fxstreet.com/cryptocurrencies/news/bitcoin-on-track-for-mass-adoption-as-it-grows-faster-than-the-internet-202102100825

10. keziesuemo. (2021, October 15). Analysis Shows that about 85% of Circulating Bitcoin Has Not Been Sold in over Three Months. Remitano. https://remitano.com/news/dk/post/13973-analysis-shows-that-about-85-percent-of-circulating-bitcoin-has-not-been-sold-in-over-three-months

11. Kutzkov, K. (2022, November 14). ARIMA vs Prophet vs LSTM for Time Series Prediction. neptune.ai. https://neptune.ai/blog/arima-vs-prophet-vs-lstm

12. Mean Squared Error: Definition and Example. (2021, June 26). Statistics How To. https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/mean-squared-error/

13. Metcalfe’s Law - calculator. (n.d.). fxSolver. https://www.fxsolver.com/browse/formulas/Metcalfe%E2%80%99s+Law

14. Next Bitcoin Halving 2024 Date & Countdown [BTC Clock]. (n.d.). https://buybitcoinworldwide.com/halving/

15. Otto, M. J. T. (n.d.). Bootstrap. https://getbootstrap.com/

16. Snow, R. (2022, February 7). 200 Day Moving Average: What it is and How it Works. DailyFX. https://www.dailyfx.com/education/moving-averages/200-day-moving-average.html

17. Taylor, S. J., & Letham, B. (2017). Forecasting at scale. PeerJ. https://doi.org/10.7287/peerj.preprints.3190v2

18. Wikipedia contributors. (2022, November 7). Bitcoin. Wikipedia. https://en.wikipedia.org/wiki/Bitcoin

19. Zach. (2020, November 4). What is Overfitting in Machine Learning? (Explanation & Examples). Statology. https://www.statology.org/overfitting-machine-learning/

20. Mathieu Blondel, Hamzeh Alsalhi. (March 18, 2022 Last Commit). OneVsRestClassifier. scikit learn. Github. https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html, https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/multiclass.py#L187
